{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 MULTICLASS CLASSIFICATION SETUP\n",
            "==================================================\n",
            "✅ Libraries imported (including Optuna)\n",
            "✅ Paths configured\n",
            "✅ Model directory created\n",
            "🎯 Target: Multiclass Classification (Grade Categories)\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Setup and Data Loading\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Paths\n",
        "TRAIN_PATH = \"../data/train_processed_comprehensive.csv\"\n",
        "TEST_PATH = \"../data/test_processed_comprehensive.csv\"\n",
        "MODEL_PATH = \"../models/academic_risk_model.joblib\"\n",
        "os.makedirs(\"../models\", exist_ok=True)\n",
        "\n",
        "print(\"🚀 MULTICLASS CLASSIFICATION SETUP\")\n",
        "print(\"=\" * 50)\n",
        "print(\"✅ Libraries imported (including Optuna)\")\n",
        "print(\"✅ Paths configured\")\n",
        "print(\"✅ Model directory created\")\n",
        "print(\"🎯 Target: Multiclass Classification (Grade Categories)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 LOADING DATA AND CONVERTING TO MULTICLASS CLASSIFICATION\n",
            "============================================================\n",
            "✅ Training data: 3,281 samples, 143 features\n",
            "✅ Test data: 821 samples, 143 features\n",
            "🔍 Checking feature types...\n",
            "   Total columns: 144\n",
            "   Feature columns: 140\n",
            "   ID columns: 2\n",
            "   Target column: grade_category\n",
            "⚠️ Found non-numerical features: ['grade']\n",
            "   Removing non-numerical features...\n",
            "   Updated feature columns: 139\n",
            "\n",
            "✅ Final feature matrix shape: (3281, 139)\n",
            "✅ Target vector shape: (3281,)\n",
            "✅ Target classes: ['A', 'B', 'C', 'D', 'F']\n",
            "\n",
            "🔧 Encoding target labels...\n",
            "   Original classes: ['A', 'B', 'C', 'D', 'F']\n",
            "   Encoded classes: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4)]\n",
            "   Class mapping: {'A': np.int64(0), 'B': np.int64(1), 'C': np.int64(2), 'D': np.int64(3), 'F': np.int64(4)}\n",
            "\n",
            "📊 Dataset Overview:\n",
            "   Features: 139\n",
            "   Target: Grade Categories (A, B, C, D, F)\n",
            "   Training samples: 3,281\n",
            "   Test samples: 821\n",
            "\n",
            "📊 Target Distribution (Training):\n",
            "   Grade A: 1,011 samples (30.8%)\n",
            "   Grade B: 987 samples (30.1%)\n",
            "   Grade C: 901 samples (27.5%)\n",
            "   Grade D: 344 samples (10.5%)\n",
            "   Grade F: 38 samples (1.2%)\n",
            "\n",
            "📊 Target Distribution (Test):\n",
            "   Grade B: 273 samples (33.3%)\n",
            "   Grade A: 234 samples (28.5%)\n",
            "   Grade C: 226 samples (27.5%)\n",
            "   Grade D: 79 samples (9.6%)\n",
            "   Grade F: 9 samples (1.1%)\n",
            "\n",
            "✅ No missing values in training data\n",
            "\n",
            "📊 Class Balance Analysis:\n",
            "   Number of classes: 5\n",
            "   Most frequent class: A (1011 samples)\n",
            "   Least frequent class: F (38 samples)\n",
            "   Class imbalance ratio: 26.61:1\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Load Data and Convert to Multiclass Classification\n",
        "print(\"📊 LOADING DATA AND CONVERTING TO MULTICLASS CLASSIFICATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load the comprehensive processed datasets\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "test_df = pd.read_csv(TEST_PATH)\n",
        "\n",
        "print(f\"✅ Training data: {train_df.shape[0]:,} samples, {train_df.shape[1]} features\")\n",
        "print(f\"✅ Test data: {test_df.shape[0]:,} samples, {test_df.shape[1]} features\")\n",
        "\n",
        "# Convert GPA to Grade Categories for Multiclass Classification\n",
        "def gpa_to_grade_category(gpa):\n",
        "    \"\"\"Convert GPA to grade categories for multiclass classification\"\"\"\n",
        "    if gpa >= 3.7:\n",
        "        return 'A'  # A, A-\n",
        "    elif gpa >= 3.0:\n",
        "        return 'B'  # B+, B, B-\n",
        "    elif gpa >= 2.0:\n",
        "        return 'C'  # C+, C, C-\n",
        "    elif gpa >= 1.0:\n",
        "        return 'D'  # D+, D\n",
        "    else:\n",
        "        return 'F'  # F\n",
        "\n",
        "# Apply grade category conversion\n",
        "train_df['grade_category'] = train_df['gpa'].apply(gpa_to_grade_category)\n",
        "test_df['grade_category'] = test_df['gpa'].apply(gpa_to_grade_category)\n",
        "\n",
        "# Prepare features and target\n",
        "id_cols = [\"student_id\", \"course_id\"]\n",
        "target_col = \"grade_category\"\n",
        "feature_cols = [c for c in train_df.columns if c not in id_cols + [target_col, 'gpa']]\n",
        "\n",
        "# Ensure we only have numerical features\n",
        "print(f\"🔍 Checking feature types...\")\n",
        "print(f\"   Total columns: {len(train_df.columns)}\")\n",
        "print(f\"   Feature columns: {len(feature_cols)}\")\n",
        "print(f\"   ID columns: {len(id_cols)}\")\n",
        "print(f\"   Target column: {target_col}\")\n",
        "\n",
        "# Check for any non-numerical features\n",
        "non_numerical = train_df[feature_cols].select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "if non_numerical:\n",
        "    print(f\"⚠️ Found non-numerical features: {non_numerical}\")\n",
        "    print(\"   Removing non-numerical features...\")\n",
        "    feature_cols = [c for c in feature_cols if c not in non_numerical]\n",
        "    print(f\"   Updated feature columns: {len(feature_cols)}\")\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df[target_col]\n",
        "X_test = test_df[feature_cols]\n",
        "y_test = test_df[target_col]\n",
        "\n",
        "print(f\"\\n✅ Final feature matrix shape: {X_train.shape}\")\n",
        "print(f\"✅ Target vector shape: {y_train.shape}\")\n",
        "print(f\"✅ Target classes: {sorted(y_train.unique())}\")\n",
        "\n",
        "# Store original target values for display\n",
        "y_train_original = y_train.copy()\n",
        "y_test_original = y_test.copy()\n",
        "\n",
        "# Encode target labels to numerical values for some algorithms\n",
        "print(f\"\\n🔧 Encoding target labels...\")\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "print(f\"   Original classes: {sorted(y_train.unique())}\")\n",
        "print(f\"   Encoded classes: {sorted(np.unique(y_train_encoded))}\")\n",
        "print(f\"   Class mapping: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\")\n",
        "\n",
        "# Use encoded targets for training\n",
        "y_train = y_train_encoded\n",
        "y_test = y_test_encoded\n",
        "\n",
        "print(f\"\\n📊 Dataset Overview:\")\n",
        "print(f\"   Features: {len(feature_cols)}\")\n",
        "print(f\"   Target: Grade Categories (A, B, C, D, F)\")\n",
        "print(f\"   Training samples: {len(X_train):,}\")\n",
        "print(f\"   Test samples: {len(X_test):,}\")\n",
        "\n",
        "print(f\"\\n📊 Target Distribution (Training):\")\n",
        "grade_dist = pd.Series(y_train_original).value_counts()\n",
        "for grade, count in grade_dist.items():\n",
        "    print(f\"   Grade {grade}: {count:,} samples ({count/len(y_train_original)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\n📊 Target Distribution (Test):\")\n",
        "test_grade_dist = pd.Series(y_test_original).value_counts()\n",
        "for grade, count in test_grade_dist.items():\n",
        "    print(f\"   Grade {grade}: {count:,} samples ({count/len(y_test_original)*100:.1f}%)\")\n",
        "\n",
        "# Check for any missing values\n",
        "if X_train.isna().sum().sum() > 0 or np.isnan(y_train).sum() > 0:\n",
        "    print(f\"\\n⚠️ Missing values detected!\")\n",
        "    print(f\"   X_train missing: {X_train.isna().sum().sum()}\")\n",
        "    print(f\"   y_train missing: {np.isnan(y_train).sum()}\")\n",
        "else:\n",
        "    print(f\"\\n✅ No missing values in training data\")\n",
        "\n",
        "# Check class balance\n",
        "print(f\"\\n📊 Class Balance Analysis:\")\n",
        "print(f\"   Number of classes: {len(grade_dist)}\")\n",
        "print(f\"   Most frequent class: {grade_dist.idxmax()} ({grade_dist.max()} samples)\")\n",
        "print(f\"   Least frequent class: {grade_dist.idxmin()} ({grade_dist.min()} samples)\")\n",
        "print(f\"   Class imbalance ratio: {grade_dist.max() / grade_dist.min():.2f}:1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 TRAINING BASELINE CLASSIFICATION MODELS\n",
            "==================================================\n",
            "📊 Training Logistic Regression...\n",
            "✅ Logistic Regression Results:\n",
            "   Accuracy: 0.3386\n",
            "   F1-Score: 0.3246\n",
            "   Precision: 0.3262\n",
            "   Recall: 0.3386\n",
            "\n",
            "📊 Training Decision Tree...\n",
            "✅ Decision Tree Results:\n",
            "   Accuracy: 0.3045\n",
            "   F1-Score: 0.2956\n",
            "   Precision: 0.2924\n",
            "   Recall: 0.3045\n",
            "\n",
            "📊 Training Random Forest...\n",
            "✅ Random Forest Results:\n",
            "   Accuracy: 0.3520\n",
            "   F1-Score: 0.3275\n",
            "   Precision: 0.3183\n",
            "   Recall: 0.3520\n",
            "\n",
            "📊 Baseline Model Comparison:\n",
            "   Logistic Regression F1: 0.3246\n",
            "   Decision Tree F1: 0.2956\n",
            "   Random Forest F1: 0.3275\n",
            "\n",
            "🏆 Best Baseline: Random Forest (F1 = 0.3275)\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Baseline Classification Models\n",
        "print(\"🎯 TRAINING BASELINE CLASSIFICATION MODELS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 1. Logistic Regression (Baseline)\n",
        "print(\"📊 Training Logistic Regression...\")\n",
        "lr_model = LogisticRegression(\n",
        "    multi_class='ovr',  # One-vs-Rest for multiclass\n",
        "    max_iter=1000,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
        "lr_f1 = f1_score(y_test, y_pred_lr, average='weighted')\n",
        "lr_precision = precision_score(y_test, y_pred_lr, average='weighted')\n",
        "lr_recall = recall_score(y_test, y_pred_lr, average='weighted')\n",
        "\n",
        "print(f\"✅ Logistic Regression Results:\")\n",
        "print(f\"   Accuracy: {lr_accuracy:.4f}\")\n",
        "print(f\"   F1-Score: {lr_f1:.4f}\")\n",
        "print(f\"   Precision: {lr_precision:.4f}\")\n",
        "print(f\"   Recall: {lr_recall:.4f}\")\n",
        "\n",
        "# 2. Decision Tree\n",
        "print(\"\\n📊 Training Decision Tree...\")\n",
        "dt_model = DecisionTreeClassifier(\n",
        "    max_depth=10,\n",
        "    min_samples_split=20,\n",
        "    min_samples_leaf=10,\n",
        "    random_state=42\n",
        ")\n",
        "dt_model.fit(X_train, y_train)\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "\n",
        "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
        "dt_f1 = f1_score(y_test, y_pred_dt, average='weighted')\n",
        "dt_precision = precision_score(y_test, y_pred_dt, average='weighted')\n",
        "dt_recall = recall_score(y_test, y_pred_dt, average='weighted')\n",
        "\n",
        "print(f\"✅ Decision Tree Results:\")\n",
        "print(f\"   Accuracy: {dt_accuracy:.4f}\")\n",
        "print(f\"   F1-Score: {dt_f1:.4f}\")\n",
        "print(f\"   Precision: {dt_precision:.4f}\")\n",
        "print(f\"   Recall: {dt_recall:.4f}\")\n",
        "\n",
        "# 3. Random Forest\n",
        "print(\"\\n📊 Training Random Forest...\")\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    min_samples_split=20,\n",
        "    min_samples_leaf=10,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "rf_f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "rf_precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "rf_recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "print(f\"✅ Random Forest Results:\")\n",
        "print(f\"   Accuracy: {rf_accuracy:.4f}\")\n",
        "print(f\"   F1-Score: {rf_f1:.4f}\")\n",
        "print(f\"   Precision: {rf_precision:.4f}\")\n",
        "print(f\"   Recall: {rf_recall:.4f}\")\n",
        "\n",
        "# Compare baselines\n",
        "print(f\"\\n📊 Baseline Model Comparison:\")\n",
        "print(f\"   Logistic Regression F1: {lr_f1:.4f}\")\n",
        "print(f\"   Decision Tree F1: {dt_f1:.4f}\")\n",
        "print(f\"   Random Forest F1: {rf_f1:.4f}\")\n",
        "\n",
        "best_baseline = max([(lr_f1, \"Logistic Regression\"), (dt_f1, \"Decision Tree\"), (rf_f1, \"Random Forest\")])\n",
        "print(f\"\\n🏆 Best Baseline: {best_baseline[1]} (F1 = {best_baseline[0]:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 02:58:48,453] A new study created in memory with name: no-name-db2d43d7-51e6-4386-a490-77ebdba39df7\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 LIGHTGBM WITH OPTUNA HYPERPARAMETER TUNING\n",
            "============================================================\n",
            "🔍 Creating Optuna study...\n",
            "🚀 Running 50 optimization trials...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.309626:   2%|▏         | 1/50 [00:06<05:15,  6.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 02:58:54,890] Trial 0 finished with value: 0.3096259965694667 and parameters: {'n_estimators': 250, 'learning_rate': 0.2536999076681771, 'max_depth': 10, 'num_leaves': 64, 'subsample': 0.6624074561769746, 'colsample_bytree': 0.662397808134481, 'reg_alpha': 0.05808361216819946, 'reg_lambda': 0.8661761457749352, 'min_child_samples': 64}. Best is trial 0 with value: 0.3096259965694667.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.309626:   4%|▍         | 2/50 [00:18<07:51,  9.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 02:59:07,088] Trial 1 finished with value: 0.3073591516661131 and parameters: {'n_estimators': 383, 'learning_rate': 0.010725209743171997, 'max_depth': 12, 'num_leaves': 85, 'subsample': 0.6849356442713105, 'colsample_bytree': 0.6727299868828402, 'reg_alpha': 0.18340450985343382, 'reg_lambda': 0.3042422429595377, 'min_child_samples': 57}. Best is trial 0 with value: 0.3096259965694667.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.309626:   6%|▌         | 3/50 [00:26<07:00,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 02:59:14,992] Trial 2 finished with value: 0.29739861801828615 and parameters: {'n_estimators': 273, 'learning_rate': 0.02692655251486473, 'max_depth': 9, 'num_leaves': 22, 'subsample': 0.7168578594140872, 'colsample_bytree': 0.7465447373174766, 'reg_alpha': 0.45606998421703593, 'reg_lambda': 0.7851759613930136, 'min_child_samples': 28}. Best is trial 0 with value: 0.3096259965694667.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.309626:   8%|▊         | 4/50 [00:29<04:55,  6.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 02:59:17,522] Trial 3 finished with value: 0.3006822282458555 and parameters: {'n_estimators': 306, 'learning_rate': 0.07500118950416987, 'max_depth': 3, 'num_leaves': 65, 'subsample': 0.6682096494749166, 'colsample_bytree': 0.6260206371941118, 'reg_alpha': 0.9488855372533332, 'reg_lambda': 0.9656320330745594, 'min_child_samples': 83}. Best is trial 0 with value: 0.3096259965694667.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.309626:  10%|█         | 5/50 [00:38<05:40,  7.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 02:59:27,108] Trial 4 finished with value: 0.3090865242100041 and parameters: {'n_estimators': 222, 'learning_rate': 0.013940346079873234, 'max_depth': 9, 'num_leaves': 50, 'subsample': 0.6488152939379115, 'colsample_bytree': 0.798070764044508, 'reg_alpha': 0.034388521115218396, 'reg_lambda': 0.9093204020787821, 'min_child_samples': 33}. Best is trial 0 with value: 0.3096259965694667.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.309626:  12%|█▏        | 6/50 [00:46<05:44,  7.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 02:59:35,439] Trial 5 finished with value: 0.2993314587790193 and parameters: {'n_estimators': 365, 'learning_rate': 0.028869220380495747, 'max_depth': 8, 'num_leaves': 59, 'subsample': 0.6739417822102108, 'colsample_bytree': 0.9878338511058234, 'reg_alpha': 0.7751328233611146, 'reg_lambda': 0.9394989415641891, 'min_child_samples': 91}. Best is trial 0 with value: 0.3096259965694667.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.309626:  14%|█▍        | 7/50 [00:49<04:25,  6.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 02:59:38,245] Trial 6 finished with value: 0.30657240848590894 and parameters: {'n_estimators': 339, 'learning_rate': 0.22999586428143734, 'max_depth': 3, 'num_leaves': 27, 'subsample': 0.6180909155642152, 'colsample_bytree': 0.7301321323053057, 'reg_alpha': 0.388677289689482, 'reg_lambda': 0.2713490317738959, 'min_child_samples': 85}. Best is trial 0 with value: 0.3096259965694667.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.309626:  16%|█▌        | 8/50 [00:56<04:25,  6.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 02:59:44,873] Trial 7 finished with value: 0.3062309886504992 and parameters: {'n_estimators': 243, 'learning_rate': 0.026000059117302653, 'max_depth': 8, 'num_leaves': 22, 'subsample': 0.9208787923016158, 'colsample_bytree': 0.6298202574719083, 'reg_alpha': 0.9868869366005173, 'reg_lambda': 0.7722447692966574, 'min_child_samples': 28}. Best is trial 0 with value: 0.3096259965694667.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.309626:  18%|█▊        | 9/50 [00:58<03:25,  5.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 02:59:46,979] Trial 8 finished with value: 0.30480672522546626 and parameters: {'n_estimators': 102, 'learning_rate': 0.16015312171361207, 'max_depth': 10, 'num_leaves': 76, 'subsample': 0.9085081386743783, 'colsample_bytree': 0.6296178606936361, 'reg_alpha': 0.3584657285442726, 'reg_lambda': 0.11586905952512971, 'min_child_samples': 88}. Best is trial 0 with value: 0.3096259965694667.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.309626:  20%|██        | 10/50 [01:01<02:58,  4.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 02:59:50,240] Trial 9 finished with value: 0.30906886792406896 and parameters: {'n_estimators': 349, 'learning_rate': 0.030816017044468066, 'max_depth': 3, 'num_leaves': 38, 'subsample': 0.7300733288106988, 'colsample_bytree': 0.8918424713352257, 'reg_alpha': 0.6375574713552131, 'reg_lambda': 0.8872127425763265, 'min_child_samples': 52}. Best is trial 0 with value: 0.3096259965694667.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.309626:  22%|██▏       | 11/50 [01:12<04:03,  6.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:00:00,477] Trial 10 finished with value: 0.30035751458975174 and parameters: {'n_estimators': 478, 'learning_rate': 0.10251868762308501, 'max_depth': 6, 'num_leaves': 94, 'subsample': 0.8085360047450806, 'colsample_bytree': 0.8760988294276582, 'reg_alpha': 0.015144237102756877, 'reg_lambda': 0.6233765186294654, 'min_child_samples': 61}. Best is trial 0 with value: 0.3096259965694667.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 0. Best value: 0.309626:  24%|██▍       | 12/50 [01:22<04:49,  7.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:00:11,266] Trial 11 finished with value: 0.30647569989204365 and parameters: {'n_estimators': 187, 'learning_rate': 0.010555894926322258, 'max_depth': 11, 'num_leaves': 45, 'subsample': 0.7898925643930463, 'colsample_bytree': 0.8226010179005339, 'reg_alpha': 0.011732157206912234, 'reg_lambda': 0.5732909776512292, 'min_child_samples': 11}. Best is trial 0 with value: 0.3096259965694667.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  26%|██▌       | 13/50 [01:28<04:21,  7.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:00:17,101] Trial 12 finished with value: 0.3122474266264243 and parameters: {'n_estimators': 189, 'learning_rate': 0.055808692324215654, 'max_depth': 7, 'num_leaves': 47, 'subsample': 0.6109470798815742, 'colsample_bytree': 0.7413584553307843, 'reg_alpha': 0.2082802661088238, 'reg_lambda': 0.7299436732862953, 'min_child_samples': 41}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  28%|██▊       | 14/50 [01:31<03:33,  5.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:00:20,333] Trial 13 finished with value: 0.3068131914788604 and parameters: {'n_estimators': 150, 'learning_rate': 0.2820997924290723, 'max_depth': 6, 'num_leaves': 65, 'subsample': 0.6010360207662125, 'colsample_bytree': 0.7056228746417736, 'reg_alpha': 0.2196098336030803, 'reg_lambda': 0.7114870148644771, 'min_child_samples': 69}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  30%|███       | 15/50 [01:34<02:53,  4.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:00:23,081] Trial 14 finished with value: 0.3030826461053277 and parameters: {'n_estimators': 163, 'learning_rate': 0.05496385473733053, 'max_depth': 6, 'num_leaves': 11, 'subsample': 0.7864727961201929, 'colsample_bytree': 0.7766589954827275, 'reg_alpha': 0.20221545090113216, 'reg_lambda': 0.39998069938371494, 'min_child_samples': 42}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  32%|███▏      | 16/50 [01:38<02:33,  4.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:00:26,534] Trial 15 finished with value: 0.2966118531137734 and parameters: {'n_estimators': 205, 'learning_rate': 0.13166430498914292, 'max_depth': 5, 'num_leaves': 77, 'subsample': 0.8561711433906498, 'colsample_bytree': 0.684972690542045, 'reg_alpha': 0.28563058573467925, 'reg_lambda': 0.503553535027425, 'min_child_samples': 71}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  34%|███▍      | 17/50 [01:42<02:23,  4.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:00:30,514] Trial 16 finished with value: 0.30794286751976485 and parameters: {'n_estimators': 101, 'learning_rate': 0.05776716725148537, 'max_depth': 10, 'num_leaves': 45, 'subsample': 0.731194128587385, 'colsample_bytree': 0.8378953523354642, 'reg_alpha': 0.5940978966045696, 'reg_lambda': 0.665317673929278, 'min_child_samples': 47}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  36%|███▌      | 18/50 [01:46<02:23,  4.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:00:35,301] Trial 17 finished with value: 0.2979841675809748 and parameters: {'n_estimators': 260, 'learning_rate': 0.18066334351041807, 'max_depth': 12, 'num_leaves': 35, 'subsample': 0.602481017250404, 'colsample_bytree': 0.6682570583344382, 'reg_alpha': 0.1276665102082612, 'reg_lambda': 0.8221449765610106, 'min_child_samples': 100}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  38%|███▊      | 19/50 [01:59<03:38,  7.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:00:48,377] Trial 18 finished with value: 0.30390512136445963 and parameters: {'n_estimators': 450, 'learning_rate': 0.09691933397433788, 'max_depth': 7, 'num_leaves': 61, 'subsample': 0.6386640354069466, 'colsample_bytree': 0.73964158693172, 'reg_alpha': 0.11072341297753602, 'reg_lambda': 0.48284864646139225, 'min_child_samples': 14}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  40%|████      | 20/50 [02:11<04:10,  8.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:00:59,742] Trial 19 finished with value: 0.31179968707618183 and parameters: {'n_estimators': 296, 'learning_rate': 0.04302553031342478, 'max_depth': 10, 'num_leaves': 100, 'subsample': 0.704724304243577, 'colsample_bytree': 0.6028550510494292, 'reg_alpha': 0.3464445264801279, 'reg_lambda': 0.9978407794240471, 'min_child_samples': 38}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  42%|████▏     | 21/50 [02:19<04:02,  8.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:01:08,137] Trial 20 finished with value: 0.2954123198977115 and parameters: {'n_estimators': 417, 'learning_rate': 0.03724758407777502, 'max_depth': 5, 'num_leaves': 95, 'subsample': 0.971241147293149, 'colsample_bytree': 0.9579418118176919, 'reg_alpha': 0.5102871570417014, 'reg_lambda': 0.011620961627553272, 'min_child_samples': 38}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  44%|████▍     | 22/50 [02:35<05:00, 10.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:01:24,409] Trial 21 finished with value: 0.3035287481392433 and parameters: {'n_estimators': 295, 'learning_rate': 0.01844806551932516, 'max_depth': 10, 'num_leaves': 73, 'subsample': 0.6942053969211587, 'colsample_bytree': 0.6233175974124288, 'reg_alpha': 0.32266284894222735, 'reg_lambda': 0.8521285531827102, 'min_child_samples': 22}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  46%|████▌     | 23/50 [02:44<04:32, 10.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:01:33,036] Trial 22 finished with value: 0.29845806115652734 and parameters: {'n_estimators': 313, 'learning_rate': 0.03786946567907278, 'max_depth': 9, 'num_leaves': 100, 'subsample': 0.7658313612926888, 'colsample_bytree': 0.6622117239974942, 'reg_alpha': 0.2698216289672999, 'reg_lambda': 0.9974698284809731, 'min_child_samples': 63}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  48%|████▊     | 24/50 [02:52<04:09,  9.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:01:41,446] Trial 23 finished with value: 0.30218370303969694 and parameters: {'n_estimators': 235, 'learning_rate': 0.0722675139571516, 'max_depth': 11, 'num_leaves': 83, 'subsample': 0.6435507928070006, 'colsample_bytree': 0.7062115493275856, 'reg_alpha': 0.1199389344130884, 'reg_lambda': 0.729424439040219, 'min_child_samples': 46}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  50%|█████     | 25/50 [02:56<03:12,  7.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:01:44,706] Trial 24 finished with value: 0.3050597686550402 and parameters: {'n_estimators': 157, 'learning_rate': 0.041150936002421076, 'max_depth': 7, 'num_leaves': 53, 'subsample': 0.7510913897332896, 'colsample_bytree': 0.6126486621390768, 'reg_alpha': 0.4058796710792996, 'reg_lambda': 0.8433437293330825, 'min_child_samples': 74}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  52%|█████▏    | 26/50 [03:05<03:16,  8.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:01:54,105] Trial 25 finished with value: 0.3091180986262552 and parameters: {'n_estimators': 278, 'learning_rate': 0.019252362836923026, 'max_depth': 11, 'num_leaves': 35, 'subsample': 0.6969578558361657, 'colsample_bytree': 0.6012924677097552, 'reg_alpha': 0.09739517002761997, 'reg_lambda': 0.9807821489745049, 'min_child_samples': 50}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  54%|█████▍    | 27/50 [03:12<03:01,  7.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:02:01,211] Trial 26 finished with value: 0.30932895560662577 and parameters: {'n_estimators': 202, 'learning_rate': 0.07788578037838091, 'max_depth': 8, 'num_leaves': 68, 'subsample': 0.6365421054673541, 'colsample_bytree': 0.6552828383780902, 'reg_alpha': 0.22385222076348227, 'reg_lambda': 0.6917125190300659, 'min_child_samples': 37}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  56%|█████▌    | 28/50 [03:28<03:46, 10.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:02:17,226] Trial 27 finished with value: 0.3097761942056945 and parameters: {'n_estimators': 324, 'learning_rate': 0.04808168512897296, 'max_depth': 9, 'num_leaves': 85, 'subsample': 0.8432899406365262, 'colsample_bytree': 0.7610653810021236, 'reg_alpha': 0.5001657985189769, 'reg_lambda': 0.8970593166535472, 'min_child_samples': 21}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  58%|█████▊    | 29/50 [03:46<04:20, 12.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:02:34,569] Trial 28 finished with value: 0.30354196154478225 and parameters: {'n_estimators': 385, 'learning_rate': 0.04790225423379599, 'max_depth': 9, 'num_leaves': 87, 'subsample': 0.8526333921184073, 'colsample_bytree': 0.7777605241655242, 'reg_alpha': 0.5212967199807143, 'reg_lambda': 0.7691365091205239, 'min_child_samples': 17}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  60%|██████    | 30/50 [03:57<04:02, 12.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:02:45,911] Trial 29 finished with value: 0.3074841691173226 and parameters: {'n_estimators': 330, 'learning_rate': 0.06106320771972141, 'max_depth': 7, 'num_leaves': 91, 'subsample': 0.8168079219235658, 'colsample_bytree': 0.859210419207521, 'reg_alpha': 0.667985108272492, 'reg_lambda': 0.9147783724727612, 'min_child_samples': 24}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  62%|██████▏   | 31/50 [04:03<03:12, 10.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:02:51,528] Trial 30 finished with value: 0.29896785985479224 and parameters: {'n_estimators': 136, 'learning_rate': 0.045431725662237375, 'max_depth': 8, 'num_leaves': 100, 'subsample': 0.8420163220109168, 'colsample_bytree': 0.928105658304223, 'reg_alpha': 0.7287733564458421, 'reg_lambda': 0.5854437140381376, 'min_child_samples': 33}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  64%|██████▍   | 32/50 [04:10<02:48,  9.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:02:58,947] Trial 31 finished with value: 0.3063414817336862 and parameters: {'n_estimators': 259, 'learning_rate': 0.10234226244430565, 'max_depth': 12, 'num_leaves': 84, 'subsample': 0.6689718860925683, 'colsample_bytree': 0.7010563725549498, 'reg_alpha': 0.44853221119513076, 'reg_lambda': 0.852696466338004, 'min_child_samples': 56}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  66%|██████▌   | 33/50 [04:21<02:45,  9.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:03:09,609] Trial 32 finished with value: 0.30801098917843367 and parameters: {'n_estimators': 286, 'learning_rate': 0.021793190071613823, 'max_depth': 10, 'num_leaves': 81, 'subsample': 0.8913735708174502, 'colsample_bytree': 0.7645930912587906, 'reg_alpha': 0.1668367861364233, 'reg_lambda': 0.7959478041823813, 'min_child_samples': 43}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.312247:  68%|██████▊   | 34/50 [04:29<02:27,  9.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:03:17,634] Trial 33 finished with value: 0.30977059551060515 and parameters: {'n_estimators': 311, 'learning_rate': 0.13044351632394663, 'max_depth': 9, 'num_leaves': 90, 'subsample': 0.7155605794824682, 'colsample_bytree': 0.7281654271859975, 'reg_alpha': 0.302427739889209, 'reg_lambda': 0.9995599699441596, 'min_child_samples': 20}. Best is trial 12 with value: 0.3122474266264243.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 34. Best value: 0.313802:  70%|███████   | 35/50 [04:37<02:15,  9.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:03:26,285] Trial 34 finished with value: 0.31380206837823194 and parameters: {'n_estimators': 395, 'learning_rate': 0.12086552797249225, 'max_depth': 9, 'num_leaves': 92, 'subsample': 0.7650723155381586, 'colsample_bytree': 0.800569795502006, 'reg_alpha': 0.3230337031045488, 'reg_lambda': 0.948240665286624, 'min_child_samples': 20}. Best is trial 34 with value: 0.31380206837823194.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 34. Best value: 0.313802:  72%|███████▏  | 36/50 [04:49<02:19,  9.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:03:38,443] Trial 35 finished with value: 0.3090347774838455 and parameters: {'n_estimators': 406, 'learning_rate': 0.0690071596799701, 'max_depth': 9, 'num_leaves': 95, 'subsample': 0.7607284879416079, 'colsample_bytree': 0.8059603158780498, 'reg_alpha': 0.4525988308191177, 'reg_lambda': 0.920841445712783, 'min_child_samples': 30}. Best is trial 34 with value: 0.31380206837823194.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 34. Best value: 0.313802:  74%|███████▍  | 37/50 [05:05<02:31, 11.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:03:53,950] Trial 36 finished with value: 0.30521384027262094 and parameters: {'n_estimators': 368, 'learning_rate': 0.014564114265794946, 'max_depth': 10, 'num_leaves': 71, 'subsample': 0.8256816271223836, 'colsample_bytree': 0.759980421172767, 'reg_alpha': 0.35414585451901837, 'reg_lambda': 0.9319265985536321, 'min_child_samples': 36}. Best is trial 34 with value: 0.31380206837823194.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 34. Best value: 0.313802:  76%|███████▌  | 38/50 [05:24<02:47, 13.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:04:13,246] Trial 37 finished with value: 0.2976327204512904 and parameters: {'n_estimators': 436, 'learning_rate': 0.032571695627358045, 'max_depth': 8, 'num_leaves': 100, 'subsample': 0.8740679659140748, 'colsample_bytree': 0.7948687308479514, 'reg_alpha': 0.5562983897269425, 'reg_lambda': 0.8800829237280188, 'min_child_samples': 26}. Best is trial 34 with value: 0.31380206837823194.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 34. Best value: 0.313802:  78%|███████▊  | 39/50 [05:37<02:29, 13.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:04:26,019] Trial 38 finished with value: 0.3091243379088866 and parameters: {'n_estimators': 495, 'learning_rate': 0.084083248728327, 'max_depth': 9, 'num_leaves': 79, 'subsample': 0.7839032420618607, 'colsample_bytree': 0.8277100228352468, 'reg_alpha': 0.40447841880978913, 'reg_lambda': 0.7506952025471694, 'min_child_samples': 10}. Best is trial 34 with value: 0.31380206837823194.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 34. Best value: 0.313802:  80%|████████  | 40/50 [05:43<01:53, 11.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:04:32,242] Trial 39 finished with value: 0.3026963890168756 and parameters: {'n_estimators': 394, 'learning_rate': 0.2161512504601446, 'max_depth': 11, 'num_leaves': 90, 'subsample': 0.7442509040750934, 'colsample_bytree': 0.9109841766749615, 'reg_alpha': 0.24084666021367784, 'reg_lambda': 0.9429588204984916, 'min_child_samples': 19}. Best is trial 34 with value: 0.31380206837823194.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 34. Best value: 0.313802:  82%|████████▏ | 41/50 [05:57<01:48, 12.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:04:45,707] Trial 40 finished with value: 0.30460381676240056 and parameters: {'n_estimators': 358, 'learning_rate': 0.048852968156234695, 'max_depth': 7, 'num_leaves': 58, 'subsample': 0.9511571060687568, 'colsample_bytree': 0.8014744753964063, 'reg_alpha': 0.34331901261693754, 'reg_lambda': 0.8096685255002536, 'min_child_samples': 31}. Best is trial 34 with value: 0.31380206837823194.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 34. Best value: 0.313802:  84%|████████▍ | 42/50 [06:05<01:27, 10.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:04:54,269] Trial 41 finished with value: 0.313128190372579 and parameters: {'n_estimators': 327, 'learning_rate': 0.13716590720094468, 'max_depth': 9, 'num_leaves': 91, 'subsample': 0.7107628137312193, 'colsample_bytree': 0.7286866997646168, 'reg_alpha': 0.2746986575873201, 'reg_lambda': 0.9887014339787646, 'min_child_samples': 19}. Best is trial 34 with value: 0.31380206837823194.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 34. Best value: 0.313802:  86%|████████▌ | 43/50 [06:13<01:09,  9.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:05:01,849] Trial 42 finished with value: 0.3055023818691802 and parameters: {'n_estimators': 327, 'learning_rate': 0.1287478629300098, 'max_depth': 9, 'num_leaves': 86, 'subsample': 0.69718234643494, 'colsample_bytree': 0.7294622363849571, 'reg_alpha': 0.44492487028106875, 'reg_lambda': 0.9548314539231105, 'min_child_samples': 24}. Best is trial 34 with value: 0.31380206837823194.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 34. Best value: 0.313802:  88%|████████▊ | 44/50 [06:21<00:57,  9.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:05:10,412] Trial 43 finished with value: 0.3083067793346112 and parameters: {'n_estimators': 346, 'learning_rate': 0.1764568425750286, 'max_depth': 8, 'num_leaves': 93, 'subsample': 0.7210519518117873, 'colsample_bytree': 0.7543830645917659, 'reg_alpha': 0.16592547046835798, 'reg_lambda': 0.882729271994338, 'min_child_samples': 16}. Best is trial 34 with value: 0.31380206837823194.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 34. Best value: 0.313802:  90%|█████████ | 45/50 [06:34<00:51, 10.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:05:22,736] Trial 44 finished with value: 0.3058542313814711 and parameters: {'n_estimators': 426, 'learning_rate': 0.06368422932521703, 'max_depth': 10, 'num_leaves': 48, 'subsample': 0.7717776926825116, 'colsample_bytree': 0.7865244859229475, 'reg_alpha': 0.8602388794499966, 'reg_lambda': 0.9618399010447776, 'min_child_samples': 28}. Best is trial 34 with value: 0.31380206837823194.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 34. Best value: 0.313802:  92%|█████████▏| 46/50 [06:45<00:42, 10.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:05:33,824] Trial 45 finished with value: 0.304518375244512 and parameters: {'n_estimators': 370, 'learning_rate': 0.09172719612762996, 'max_depth': 8, 'num_leaves': 96, 'subsample': 0.6794391684778894, 'colsample_bytree': 0.8472688642873126, 'reg_alpha': 0.26050675796654793, 'reg_lambda': 0.27529230217095163, 'min_child_samples': 12}. Best is trial 34 with value: 0.31380206837823194.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 34. Best value: 0.313802:  94%|█████████▍| 47/50 [06:58<00:33, 11.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:05:46,755] Trial 46 finished with value: 0.3072811578741547 and parameters: {'n_estimators': 320, 'learning_rate': 0.025552864913986822, 'max_depth': 11, 'num_leaves': 87, 'subsample': 0.7072029805772403, 'colsample_bytree': 0.6445662056275994, 'reg_alpha': 0.3786887719510646, 'reg_lambda': 0.9005719613984264, 'min_child_samples': 41}. Best is trial 34 with value: 0.31380206837823194.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 34. Best value: 0.313802:  96%|█████████▌| 48/50 [07:05<00:20, 10.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:05:54,302] Trial 47 finished with value: 0.29734717309398534 and parameters: {'n_estimators': 298, 'learning_rate': 0.1229934688326258, 'max_depth': 9, 'num_leaves': 28, 'subsample': 0.6552492803630611, 'colsample_bytree': 0.7182816667372344, 'reg_alpha': 0.3117067575611571, 'reg_lambda': 0.6478892042133175, 'min_child_samples': 34}. Best is trial 34 with value: 0.31380206837823194.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 34. Best value: 0.313802:  98%|█████████▊| 49/50 [07:19<00:11, 11.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:06:07,559] Trial 48 finished with value: 0.30615546221142514 and parameters: {'n_estimators': 228, 'learning_rate': 0.1136306009836444, 'max_depth': 10, 'num_leaves': 75, 'subsample': 0.8015467078259829, 'colsample_bytree': 0.6832092718580957, 'reg_alpha': 0.056423385332759535, 'reg_lambda': 0.9941341769178521, 'min_child_samples': 20}. Best is trial 34 with value: 0.31380206837823194.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 34. Best value: 0.313802: 100%|██████████| 50/50 [07:24<00:00,  8.89s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-09-28 03:06:12,957] Trial 49 finished with value: 0.30481197974175267 and parameters: {'n_estimators': 468, 'learning_rate': 0.15888123264714096, 'max_depth': 6, 'num_leaves': 41, 'subsample': 0.7346314912783337, 'colsample_bytree': 0.8167933822916276, 'reg_alpha': 0.55710998676073, 'reg_lambda': 0.78919611985621, 'min_child_samples': 51}. Best is trial 34 with value: 0.31380206837823194.\n",
            "\n",
            "✅ Optimization Complete!\n",
            "   Best F1 Score: 0.3138\n",
            "   Best Parameters:\n",
            "     n_estimators: 395\n",
            "     learning_rate: 0.12086552797249225\n",
            "     max_depth: 9\n",
            "     num_leaves: 92\n",
            "     subsample: 0.7650723155381586\n",
            "     colsample_bytree: 0.800569795502006\n",
            "     reg_alpha: 0.3230337031045488\n",
            "     reg_lambda: 0.948240665286624\n",
            "     min_child_samples: 20\n",
            "\n",
            "📊 Training Final LightGBM with Best Parameters...\n",
            "✅ Optimized LightGBM Results:\n",
            "   Accuracy: 0.3313\n",
            "   F1-Score: 0.3207\n",
            "   Precision: 0.3159\n",
            "   Recall: 0.3313\n",
            "\n",
            "📊 Top 15 Most Important Features:\n",
            "                         feature  importance\n",
            "2   student_overall_success_rate        3089\n",
            "3          student_total_courses        1654\n",
            "6            course_success_rate         789\n",
            "0              student_community         663\n",
            "7          course_total_students         594\n",
            "52                student_emb_41         576\n",
            "74                student_emb_63         567\n",
            "62                student_emb_51         561\n",
            "18                 student_emb_7         536\n",
            "42                student_emb_31         531\n",
            "38                student_emb_27         530\n",
            "55                student_emb_44         529\n",
            "71                student_emb_60         528\n",
            "58                student_emb_47         520\n",
            "39                student_emb_28         517\n",
            "\n",
            "📊 Embedding Features Importance (Top 10):\n",
            "           feature  importance\n",
            "52  student_emb_41         576\n",
            "74  student_emb_63         567\n",
            "62  student_emb_51         561\n",
            "18   student_emb_7         536\n",
            "42  student_emb_31         531\n",
            "38  student_emb_27         530\n",
            "55  student_emb_44         529\n",
            "71  student_emb_60         528\n",
            "58  student_emb_47         520\n",
            "39  student_emb_28         517\n",
            "\n",
            "📊 Academic Features Importance:\n",
            "                         feature  importance\n",
            "2   student_overall_success_rate        3089\n",
            "3          student_total_courses        1654\n",
            "6            course_success_rate         789\n",
            "7          course_total_students         594\n",
            "4                   course_level          57\n",
            "5                 course_credits          19\n",
            "8                   prereq_count           0\n",
            "9            prereq_success_rate           0\n",
            "10             completed_prereqs           0\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: LightGBM with Optuna Hyperparameter Tuning\n",
        "print(\"🚀 LIGHTGBM WITH OPTUNA HYPERPARAMETER TUNING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Define objective function for Optuna\n",
        "def objective(trial):\n",
        "    \"\"\"Objective function for Optuna optimization\"\"\"\n",
        "    params = {\n",
        "        'objective': 'multiclass',\n",
        "        'metric': 'multi_logloss',\n",
        "        'num_class': len(np.unique(y_train)),\n",
        "        'boosting_type': 'gbdt',\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
        "        'random_state': 42,\n",
        "        'verbose': -1,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "    \n",
        "    # Use cross-validation for robust evaluation\n",
        "    model = lgb.LGBMClassifier(**params)\n",
        "    \n",
        "    # 3-fold stratified CV\n",
        "    cv_scores = cross_val_score(\n",
        "        model, X_train, y_train, \n",
        "        cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
        "        scoring='f1_weighted',\n",
        "        n_jobs=1  # Avoid nested parallelism\n",
        "    )\n",
        "    \n",
        "    return cv_scores.mean()\n",
        "\n",
        "# Create Optuna study\n",
        "print(\"🔍 Creating Optuna study...\")\n",
        "study = optuna.create_study(\n",
        "    direction='maximize',\n",
        "    sampler=optuna.samplers.TPESampler(seed=42),\n",
        "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
        ")\n",
        "\n",
        "# Run optimization\n",
        "n_trials = 50  # Good balance for this dataset size\n",
        "print(f\"🚀 Running {n_trials} optimization trials...\")\n",
        "study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "\n",
        "print(f\"\\n✅ Optimization Complete!\")\n",
        "print(f\"   Best F1 Score: {study.best_value:.4f}\")\n",
        "print(f\"   Best Parameters:\")\n",
        "for key, value in study.best_params.items():\n",
        "    print(f\"     {key}: {value}\")\n",
        "\n",
        "# Train final model with best parameters\n",
        "print(f\"\\n📊 Training Final LightGBM with Best Parameters...\")\n",
        "best_lgb_model = lgb.LGBMClassifier(**study.best_params, random_state=42, verbose=-1)\n",
        "best_lgb_model.fit(X_train, y_train)\n",
        "y_pred_lgb = best_lgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate final model\n",
        "lgb_accuracy = accuracy_score(y_test, y_pred_lgb)\n",
        "lgb_f1 = f1_score(y_test, y_pred_lgb, average='weighted')\n",
        "lgb_precision = precision_score(y_test, y_pred_lgb, average='weighted')\n",
        "lgb_recall = recall_score(y_test, y_pred_lgb, average='weighted')\n",
        "\n",
        "print(f\"✅ Optimized LightGBM Results:\")\n",
        "print(f\"   Accuracy: {lgb_accuracy:.4f}\")\n",
        "print(f\"   F1-Score: {lgb_f1:.4f}\")\n",
        "print(f\"   Precision: {lgb_precision:.4f}\")\n",
        "print(f\"   Recall: {lgb_recall:.4f}\")\n",
        "\n",
        "# Feature importance\n",
        "print(f\"\\n📊 Top 15 Most Important Features:\")\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': best_lgb_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(feature_importance.head(15))\n",
        "\n",
        "# Show embedding features importance\n",
        "embedding_features = [col for col in feature_cols if 'emb_' in col]\n",
        "embedding_importance = feature_importance[feature_importance['feature'].isin(embedding_features)]\n",
        "print(f\"\\n📊 Embedding Features Importance (Top 10):\")\n",
        "print(embedding_importance.head(10))\n",
        "\n",
        "# Show academic features importance\n",
        "academic_features = [col for col in feature_cols if 'emb_' not in col and 'community' not in col]\n",
        "academic_importance = feature_importance[feature_importance['feature'].isin(academic_features)]\n",
        "print(f\"\\n📊 Academic Features Importance:\")\n",
        "print(academic_importance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏆 MODEL COMPARISON AND SELECTION\n",
            "==================================================\n",
            "📊 Model Performance Comparison:\n",
            "                 Model  Accuracy  F1-Score  Precision  Recall\n",
            "0  Logistic Regression    0.3386    0.3246     0.3262  0.3386\n",
            "1        Decision Tree    0.3045    0.2956     0.2924  0.3045\n",
            "2        Random Forest    0.3520    0.3275     0.3183  0.3520\n",
            "3    LightGBM (Optuna)    0.3313    0.3207     0.3159  0.3313\n",
            "\n",
            "🏆 Best Model: Random Forest\n",
            "   F1-Score: 0.3275\n",
            "   Accuracy: 0.3520\n",
            "\n",
            "💾 Saving Random Forest as the final model...\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'unique'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 48\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m💾 Saving \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as the final model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Save the best model\u001b[39;00m\n\u001b[1;32m     43\u001b[0m model_package \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: final_model,\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m: model_type,\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_names\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_cols,\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrade_category\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_names\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28msorted\u001b[39m(\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m()\u001b[38;5;241m.\u001b[39mtolist()),\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperformance\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: models_comparison\u001b[38;5;241m.\u001b[39mloc[best_model_idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m'\u001b[39m: models_comparison\u001b[38;5;241m.\u001b[39mloc[best_model_idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1-Score\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m: models_comparison\u001b[38;5;241m.\u001b[39mloc[best_model_idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m: models_comparison\u001b[38;5;241m.\u001b[39mloc[best_model_idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     54\u001b[0m     },\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_samples\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(X_train),\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_samples\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(X_test),\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_features\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(feature_cols),\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptuna_params\u001b[39m\u001b[38;5;124m'\u001b[39m: study\u001b[38;5;241m.\u001b[39mbest_params \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightgbm_optimized\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     59\u001b[0m }\n\u001b[1;32m     61\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(model_package, MODEL_PATH)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Model saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'unique'"
          ]
        }
      ],
      "source": [
        "# Cell 5: Model Comparison and Selection\n",
        "print(\"🏆 MODEL COMPARISON AND SELECTION\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Compare all models\n",
        "models_comparison = pd.DataFrame({\n",
        "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'LightGBM (Optuna)'],\n",
        "    'Accuracy': [lr_accuracy, dt_accuracy, rf_accuracy, lgb_accuracy],\n",
        "    'F1-Score': [lr_f1, dt_f1, rf_f1, lgb_f1],\n",
        "    'Precision': [lr_precision, dt_precision, rf_precision, lgb_precision],\n",
        "    'Recall': [lr_recall, dt_recall, rf_recall, lgb_recall]\n",
        "})\n",
        "\n",
        "print(\"📊 Model Performance Comparison:\")\n",
        "print(models_comparison.round(4))\n",
        "\n",
        "# Find best model based on F1-Score\n",
        "best_model_idx = models_comparison['F1-Score'].idxmax()\n",
        "best_model_name = models_comparison.loc[best_model_idx, 'Model']\n",
        "best_f1 = models_comparison.loc[best_model_idx, 'F1-Score']\n",
        "\n",
        "print(f\"\\n🏆 Best Model: {best_model_name}\")\n",
        "print(f\"   F1-Score: {best_f1:.4f}\")\n",
        "print(f\"   Accuracy: {models_comparison.loc[best_model_idx, 'Accuracy']:.4f}\")\n",
        "\n",
        "# Select the best model for saving\n",
        "if best_model_name == 'Logistic Regression':\n",
        "    final_model = lr_model\n",
        "    model_type = 'logistic_regression'\n",
        "elif best_model_name == 'Decision Tree':\n",
        "    final_model = dt_model\n",
        "    model_type = 'decision_tree'\n",
        "elif best_model_name == 'Random Forest':\n",
        "    final_model = rf_model\n",
        "    model_type = 'random_forest'\n",
        "else:  # LightGBM\n",
        "    final_model = best_lgb_model\n",
        "    model_type = 'lightgbm_optimized'\n",
        "\n",
        "print(f\"\\n💾 Saving {best_model_name} as the final model...\")\n",
        "\n",
        "# Save the best model\n",
        "model_package = {\n",
        "    'model': final_model,\n",
        "    'model_type': model_type,\n",
        "    'feature_names': feature_cols,\n",
        "    'target_name': 'grade_category',\n",
        "    'class_names': sorted(y_train.unique().tolist()),\n",
        "    'performance': {\n",
        "        'accuracy': models_comparison.loc[best_model_idx, 'Accuracy'],\n",
        "        'f1_score': models_comparison.loc[best_model_idx, 'F1-Score'],\n",
        "        'precision': models_comparison.loc[best_model_idx, 'Precision'],\n",
        "        'recall': models_comparison.loc[best_model_idx, 'Recall']\n",
        "    },\n",
        "    'training_samples': len(X_train),\n",
        "    'test_samples': len(X_test),\n",
        "    'total_features': len(feature_cols),\n",
        "    'optuna_params': study.best_params if model_type == 'lightgbm_optimized' else None\n",
        "}\n",
        "\n",
        "joblib.dump(model_package, MODEL_PATH)\n",
        "print(f\"✅ Model saved to: {MODEL_PATH}\")\n",
        "\n",
        "# Detailed classification report for best model\n",
        "print(f\"\\n📊 Detailed Classification Report for {best_model_name}:\")\n",
        "print(classification_report(y_test, y_pred_lgb, target_names=label_encoder.classes_))\n",
        "\n",
        "# Confusion matrix\n",
        "print(f\"\\n📊 Confusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, y_pred_lgb)\n",
        "print(cm)\n",
        "\n",
        "# Final summary\n",
        "print(f\"\\n🎯 TRAINING COMPLETE!\")\n",
        "print(f\"📊 Final Summary:\")\n",
        "print(f\"   Best Model: {best_model_name}\")\n",
        "print(f\"   F1-Score: {best_f1:.4f}\")\n",
        "print(f\"   Training Samples: {len(X_train):,}\")\n",
        "print(f\"   Test Samples: {len(X_test):,}\")\n",
        "print(f\"   Features: {len(feature_cols)}\")\n",
        "print(f\"   Target: Grade Categories (A, B, C, D, F)\")\n",
        "print(f\"   Datasets Used: train_processed_comprehensive.csv, test_processed_comprehensive.csv\")\n",
        "print(f\"\\n🚀 Model ready for deployment!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
